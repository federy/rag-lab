{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892105ce-f8b6-4cd5-80c8-0abca5987b05",
   "metadata": {},
   "source": [
    "# Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b38784-25e1-46d8-8d18-26181922d170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1b8d13-009e-4589-a593-215b90675e31",
   "metadata": {},
   "source": [
    "# Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e223b2f-4045-446a-8393-f678211a26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.openai import AsyncOpenAI  # autoinstrmenttion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdbf19d-9643-464a-9645-893865380296",
   "metadata": {},
   "source": [
    "# Setup LLM Call Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cff8e79-588c-4586-90ea-fa556824be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f622e028-248d-411c-be07-ceb07cbb983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4O_MINI = \"gpt-4o-mini-2024-07-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4177a2-f8d6-4507-b8d0-0a48f1384013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _msg(role, content):\n",
    "    return {'role': role, 'content': content}\n",
    "\n",
    "def system(content):\n",
    "    return _msg('system', content)\n",
    "\n",
    "def user(content):\n",
    "    return _msg('user', content)\n",
    "\n",
    "def assistant(content):\n",
    "    return _msg('assistant', content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf523b-5001-456a-972a-537e9b85bfbd",
   "metadata": {},
   "source": [
    "# Cache System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e974b152-059a-4927-af65-ca3e4fad9864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diskcache import Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12234460-2cf8-44ae-b47e-299340c3e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Cache(directory=\".cache_course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a964f6a8-f2fb-4990-892e-f754d0aee253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce28600-6e67-4857-a970-6dca9ee307bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def set_async(key, val, **kwargs):\n",
    "    return await asyncio.to_thread(cache.set, key, val, **kwargs)\n",
    "\n",
    "async def get_async(key, default=None, **kwargs):\n",
    "    return await asyncio.to_thread(cache.get, key, default, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d45d042-aa12-41f8-9415-1b5b98c30a85",
   "metadata": {},
   "source": [
    "# Implementing Cached, Retried and Traced Structured Ouputs completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e834cfcf-56b1-4519-8abf-b7f316b99294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from hashlib import md5\n",
    "\n",
    "def make_cache_key(key_name, **kwargs):\n",
    "    kwargs_string = json.dumps(kwargs, sort_keys=True)\n",
    "    kwargs_hash = md5(kwargs_string.encode('utf-8')).hexdigest()\n",
    "    cache_key = f\"{key_name}__{kwargs_hash}\"\n",
    "    return cache_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95eec4f7-c72a-4adc-8226-b769d6742db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "def _make_key_for_cached_chat_completion_parsed_with_retry(\n",
    "    *,\n",
    "    model,\n",
    "    messages,\n",
    "    response_format: BaseModel,\n",
    "    **kwargs,\n",
    "):\n",
    "    return make_cache_key(\n",
    "        \"openai_parsed_chat\",\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format=response_format.model_json_schema(),\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75621a9d-a4ba-46f8-ba63-cf544a12fbbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AsyncCompletions' object has no attribute 'parse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      8\u001b[39m ResponseFormatT = TypeVar(\u001b[33m\"\u001b[39m\u001b[33mResponseFormatT\u001b[39m\u001b[33m\"\u001b[39m, bound=BaseModel)\n\u001b[32m     10\u001b[39m CACHE_MISS_SENTINEL = \u001b[38;5;28mobject\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_chat_completion_parsed_with_retry\u001b[39m(\n\u001b[32m     15\u001b[39m     *,\n\u001b[32m     16\u001b[39m     model,\n\u001b[32m     17\u001b[39m     messages,\n\u001b[32m     18\u001b[39m     response_format: ResponseFormatT,\n\u001b[32m     19\u001b[39m     **kwargs,\n\u001b[32m     20\u001b[39m ) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# CREATE CACHE KEY\u001b[39;00m\n\u001b[32m     22\u001b[39m     cache_key = _make_key_for_cached_chat_completion_parsed_with_retry(\n\u001b[32m     23\u001b[39m         model=model,\n\u001b[32m     24\u001b[39m         messages=messages,\n\u001b[32m     25\u001b[39m         response_format=response_format,\n\u001b[32m     26\u001b[39m         **kwargs\n\u001b[32m     27\u001b[39m     )\n\u001b[32m     29\u001b[39m     cached_value = \u001b[38;5;28;01mawait\u001b[39;00m get_async(cache_key, default=CACHE_MISS_SENTINEL)\n",
      "\u001b[31mAttributeError\u001b[39m: 'AsyncCompletions' object has no attribute 'parse'"
     ]
    }
   ],
   "source": [
    "from openai.types.chat import ParsedChatCompletion\n",
    "from functools import wraps\n",
    "from openai import APITimeoutError, RateLimitError\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import TypeVar\n",
    "import backoff\n",
    "\n",
    "ResponseFormatT = TypeVar(\"ResponseFormatT\", bound=BaseModel)\n",
    "\n",
    "CACHE_MISS_SENTINEL = object()\n",
    "\n",
    "\n",
    "@wraps(client.chat.completions.parse)\n",
    "async def cached_chat_completion_parsed_with_retry(\n",
    "    *,\n",
    "    model,\n",
    "    messages,\n",
    "    response_format: ResponseFormatT,\n",
    "    **kwargs,\n",
    ") -> ParsedChatCompletion[ResponseFormatT]:\n",
    "    # CREATE CACHE KEY\n",
    "    cache_key = _make_key_for_cached_chat_completion_parsed_with_retry(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format=response_format,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    cached_value = await get_async(cache_key, default=CACHE_MISS_SENTINEL)\n",
    "    # CACHE MISS\n",
    "    if cached_value is CACHE_MISS_SENTINEL:\n",
    "        @backoff.on_exception(\n",
    "            backoff.expo,\n",
    "            (APITimeoutError, RateLimitError)\n",
    "        )\n",
    "        async def do_call():\n",
    "            return await client.chat.completions.parse(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                response_format=response_format,\n",
    "                **kwargs\n",
    "            )\n",
    "        completion = await do_call()\n",
    "        await set_async(cache_key, completion.model_dump_json())\n",
    "        return completion\n",
    "    # CACHE HIT\n",
    "    else:\n",
    "        # TODO: Tracing Code (next section)\n",
    "        # return \n",
    "        completion = ParsedChatCompletion.model_validate(json.loads(cached_value))\n",
    "        for choice in completion.choices:\n",
    "            if not choice.message.refusal:\n",
    "                choice.message.parsed = response_format.model_validate(\n",
    "                    choice.message.parsed\n",
    "                )\n",
    "        return completion\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4773a04-c0fe-4e74-a78f-650fc5db47cf",
   "metadata": {},
   "source": [
    "# DATA_GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38473841-8156-434d-845f-177cbcab3b82",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af2453-2ea2-4986-a0d3-067bb11b5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d8ee2-e481-468d-b19d-5824738c828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv(\"paul_allen_sent_emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc8f83-970a-406f-af0a-1bbc0b3da48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b861b66-a89b-44db-ba1b-e44c416bb52b",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ebb3b1-e11e-42a6-9782-386b64ada179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c16ec-10f5-4351-bcb9-6d8b97fe6e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-course",
   "language": "python",
   "name": "rag-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
