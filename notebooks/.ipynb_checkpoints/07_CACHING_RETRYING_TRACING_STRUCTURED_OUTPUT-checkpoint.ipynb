{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebfcb399-4f7e-46ac-9c5d-c5e86f0f4113",
   "metadata": {},
   "source": [
    "# Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2ff697-f529-4977-aebb-de4964d79384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d631c-7dcc-40a3-98d8-a67f87d1d8f6",
   "metadata": {},
   "source": [
    "# Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb8fd5b-e4e4-40ed-a282-22803f01144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5534cf5-7738-44a6-bf1c-2f054b41119c",
   "metadata": {},
   "source": [
    "# Setup LLM Call Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa30751-6d93-4509-9c06-8d667320d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7366a2-b71e-4e1c-a4c9-d5b4185f39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4O_MINI = \"o4-mini-2025-04-16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfe91c2-120d-4bc8-ba4f-832b1a85c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _msg(role, content):\n",
    "    return {'role': role, 'content': content}\n",
    "\n",
    "def system(content):\n",
    "    return _msg('system', content)\n",
    "\n",
    "def user(content):\n",
    "    return _msg('user', content)\n",
    "\n",
    "def assistant(content):\n",
    "    return _msg('assistant', content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ace89-8280-4b20-97c5-cb49a8f84eba",
   "metadata": {},
   "source": [
    "# Cache to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0cecc49-7f8d-4ba7-8507-b4494a0f088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diskcache import Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf162f0-07b3-47a4-9512-79256d597318",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Cache(directory=\".cache_course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6d45c3-2e80-4b1c-8ef3-3b9f124caa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2453bd76-2177-40d3-a8b7-338b52075c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def set_async(key, val, **kwargs):\n",
    "    return await asyncio.to_thread(cache.set, key, val, **kwargs)\n",
    "\n",
    "async def get_async(key, default=None, **kwargs):\n",
    "    return await asyncio.to_thread(cache.get, key, default, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6dc804-6a15-4be7-869e-b85d1c69ff09",
   "metadata": {},
   "source": [
    "# Implementing Cached, Retried and Traced Structures Outputs Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66f58957-4c73-4735-9c2c-55ca43bb7eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd82a41-cd2a-4706-9cf2-c04745e71bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from hashlib import md5\n",
    "\n",
    "def make_cache_key(key_name, **kwargs):\n",
    "    kwargs_string = json.dumps(kwargs, sort_keys=True)\n",
    "    kwargs_hash = md5(kwargs_string.encode('utf-8')).hexdigest()\n",
    "    cache_key = f\"{key_name}__{kwargs_hash}\"\n",
    "    \n",
    "    return cache_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "619eaed4-c8cf-4489-822f-c3c72e867f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_key_for_cached_chat_completion_parsed_with_retry(\n",
    "    *,\n",
    "    model,\n",
    "    messages,\n",
    "    response_format: BaseModel,\n",
    "    **kwargs,\n",
    "):\n",
    "    return make_cache_key(\n",
    "        \"openai_parsed_chat\",\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format=response_format.model_json_schema(),\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e243863-6e11-4b6a-b632-698d820e7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from openai.types.responses import ParsedResponse\n",
    "from openai.types.chat import ParsedChatCompletion\n",
    "from functools import wraps\n",
    "from openai import APITimeoutError, RateLimitError\n",
    "# from pydantic import BaseModel\n",
    "from typing_extensions import TypeVar\n",
    "import backoff\n",
    "\n",
    "ResponseFormatT = TypeVar(\"ResponseFormatT\", bound=BaseModel)\n",
    "\n",
    "CACHE_MISS_SENTINEL = object()\n",
    "\n",
    "@wraps(client.chat.completions.parse)\n",
    "async def cached_chat_completion_parsed_with_retry(\n",
    "    *,\n",
    "    model,\n",
    "    messages,\n",
    "    response_format: ResponseFormatT,\n",
    "    **kwargs,\n",
    ") -> ParsedChatCompletion[ResponseFormatT]:\n",
    "    # CREATE CACHE KEY\n",
    "    cache_key = _make_key_for_cached_chat_completion_parsed_with_retry(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format=response_format,\n",
    "        **kwargs\n",
    "    )\n",
    "    cached_value = await get_async(cache_key, default=CACHE_MISS_SENTINEL)\n",
    "    \n",
    "    # CACHE MISS\n",
    "    if cached_value is CACHE_MISS_SENTINEL:\n",
    "        @backoff.on_exception(\n",
    "            backoff.expo,\n",
    "            (APITimeoutError, RateLimitError)\n",
    "        )\n",
    "        async def do_call():\n",
    "            return await client.chat.completions.parse(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                response_format=response_format,\n",
    "                **kwargs\n",
    "            )\n",
    "        completion = await do_call()\n",
    "        await set_async(cache_key, completion.model_dump_json())\n",
    "        return completion\n",
    "    # CACHE HIT\n",
    "    else:\n",
    "        completion = ParsedChatCompletion.model_validate(json.loads(cached_value))\n",
    "        for choice in completion.choices:\n",
    "            if not choice.message.refusal:\n",
    "                choice.message.parsed = response_format.model_validate(\n",
    "                    choice.message.parsed\n",
    "                )\n",
    "        return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7503ed6f-80d0-40a3-8137-c87ad8de7027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "class CalendarEvent(BaseModel):                 #####################################\n",
    "    name: str                                   ############# SCHEMA ################\n",
    "    date: str                                   #####################################\n",
    "    participants: list[str]                     #####################################\n",
    "\n",
    "completion = await cached_chat_completion_parsed_with_retry(\n",
    "    model=GPT4O_MINI,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    "    response_format=CalendarEvent,\n",
    "    # max_output_tokens=5  ### WILL NOT WORK because not enough tokens to output the full json string\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8f25ad0-8d94-4a66-800d-d115e967681a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedChatCompletion(id='chatcmpl-C5u7UShKq6BgMJhZM5O896DOUEeba', choices=[ParsedChoice(finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage(content='{\"name\":\"Science Fair\",\"date\":\"Friday\",\"participants\":[\"Alice\",\"Bob\"]}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None, parsed=CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])))], created=1755523400, model='o4-mini-2025-04-16', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=167, prompt_tokens=90, total_tokens=257, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=128, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156478a-9fd3-4a76-88a0-85008164eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f383ce-6b5f-4e92-956e-575cd340612f",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40b8c2-f176-46ff-bbf5-bb5a5b009dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of\n",
    "# client.chat.completions.create\n",
    "# use:\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CalendarEvent(BaseModel):                 #####################################\n",
    "    name: str                                   ############# SCHEMA ################\n",
    "    date: str                                   #####################################\n",
    "    participants: list[str]                     #####################################\n",
    "\n",
    "response = await client.responses.parse(\n",
    "    model=GPT4O_MINI,\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    "    text_format=CalendarEvent,\n",
    "    # max_output_tokens=5  ### WILL NOT WORK because not enough tokens to output the full json string\n",
    ")\n",
    "\n",
    "event = response.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c784b3-b8ba-499d-a714-f26a9f36ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9442d-d35a-4f99-92e4-36b0628eec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "event.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bce031-b6be-4d15-bd02-1eb0d54de197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response_as_dict = json.loads(event.model_dump_json())\n",
    "print(response_as_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f9d3fa-354f-4920-b41d-875483a865e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = CalendarEvent.model_validate(response_as_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe46fa-2105-4f78-ac08-b449e94bd8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "event.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510b66f-4948-48fd-8efc-bf193d4affdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CalendarEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c875dd-c9ca-4de5-9b5e-99a2f1052849",
   "metadata": {},
   "outputs": [],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e41d8-de01-4510-a124-6ca5bd9b1d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-course",
   "language": "python",
   "name": "rag-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
