{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c471fee9-a767-44c5-8d4d-e19a7da78599",
   "metadata": {},
   "source": [
    "# Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2babff-83c4-487f-8687-4448c266f135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c2645-a9ef-4b75-802f-ac7a92d284b7",
   "metadata": {},
   "source": [
    "# Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a678ae-de24-422a-b4ae-b8f3732a7bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ddbaf-187d-42da-9174-74618d5e9746",
   "metadata": {},
   "source": [
    "# Setup Embedding Call Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20dba67-1cfc-4bf4-b98d-eb740894f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05394430-e7ba-4e6c-8ce1-2bc55960e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_MODEL = \"text-embedding-3-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0bbc3c-749e-479a-ab99-27baa105defe",
   "metadata": {},
   "source": [
    "## Demo Embedding Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c53d76-f4d6-4be7-a4de-8a24fe97a1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "client.embeddings.create(\n",
       "    *,\n",
       "    input: \u001b[33m'Union[str, List[str], Iterable[int], Iterable[Iterable[int]]]'\u001b[39m,\n",
       "    model: \u001b[33m'Union[str, EmbeddingModel]'\u001b[39m,\n",
       "    dimensions: \u001b[33m'int | NotGiven'\u001b[39m = NOT_GIVEN,\n",
       "    encoding_format: \u001b[33m\"Literal['float', 'base64'] | NotGiven\"\u001b[39m = NOT_GIVEN,\n",
       "    user: \u001b[33m'str | NotGiven'\u001b[39m = NOT_GIVEN,\n",
       "    extra_headers: \u001b[33m'Headers | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    extra_query: \u001b[33m'Query | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    extra_body: \u001b[33m'Body | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    timeout: \u001b[33m'float | httpx.Timeout | None | NotGiven'\u001b[39m = NOT_GIVEN,\n",
       ") -> \u001b[33m'CreateEmbeddingResponse'\u001b[39m\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Creates an embedding vector representing the input text.\n",
       "\n",
       "Args:\n",
       "  input: Input text to embed, encoded as a string or array of tokens. To embed multiple\n",
       "      inputs in a single request, pass an array of strings or array of token arrays.\n",
       "      The input must not exceed the max input tokens for the model (8192 tokens for\n",
       "      all embedding models), cannot be an empty string, and any array must be 2048\n",
       "      dimensions or less.\n",
       "      [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n",
       "      for counting tokens. In addition to the per-input token limit, all embedding\n",
       "      models enforce a maximum of 300,000 tokens summed across all inputs in a single\n",
       "      request.\n",
       "\n",
       "  model: ID of the model to use. You can use the\n",
       "      [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n",
       "      see all of your available models, or see our\n",
       "      [Model overview](https://platform.openai.com/docs/models) for descriptions of\n",
       "      them.\n",
       "\n",
       "  dimensions: The number of dimensions the resulting output embeddings should have. Only\n",
       "      supported in `text-embedding-3` and later models.\n",
       "\n",
       "  encoding_format: The format to return the embeddings in. Can be either `float` or\n",
       "      [`base64`](https://pypi.org/project/pybase64/).\n",
       "\n",
       "  user: A unique identifier representing your end-user, which can help OpenAI to monitor\n",
       "      and detect abuse.\n",
       "      [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n",
       "\n",
       "  extra_headers: Send extra headers\n",
       "\n",
       "  extra_query: Add additional query parameters to the request\n",
       "\n",
       "  extra_body: Add additional JSON properties to the request\n",
       "\n",
       "  timeout: Override the client-level default timeout for this request, in seconds\n",
       "\u001b[31mFile:\u001b[39m      ~/LIVE/course/.venv/lib64/python3.12/site-packages/openai/resources/embeddings.py\n",
       "\u001b[31mType:\u001b[39m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.embeddings.create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a4c876-1286-45ac-afd2-6c1e402cb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = await client.embeddings.create(\n",
    "    input='Union[str, List[str], Iterable[int], Iterable[Iterable[int]]]',\n",
    "    model=EMBED_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe1c888-6ecc-455e-aa85-40fbeab7fc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_computed_fields__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_setattr_handlers__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__replace__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_recursion__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " '_setattr_handler',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'embedding',\n",
       " 'from_orm',\n",
       " 'index',\n",
       " 'json',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'object',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'to_dict',\n",
       " 'to_json',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(embedding.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c4921e-c251-40eb-b6ba-e5cfdb8ac808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedding.data[0].embedding[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e947a2-a433-43fb-9580-bb017d83e576",
   "metadata": {},
   "source": [
    "## Embedding Call Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55b34bb6-a6a8-4de0-bf77-f0ff1f3f865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(e) ->list[float]:\n",
    "    return e.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d11f6fb-c025-4dda-bdb4-3f8b082a7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_embedding = get_embedding(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25bf20-b1b9-4547-86b3-2172576638c2",
   "metadata": {},
   "source": [
    "# Compute Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2433edee-163e-48ed-a8e9-f525c92d1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from openai.types.create_embedding_response import CreateEmbeddingResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "856798e6-f04d-4344-840a-f66509aefadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_cosine_sim(e1: CreateEmbeddingResponse, e2: CreateEmbeddingResponse) -> float:\n",
    "    e1, e2 = get_embedding(e1), get_embedding(e2)\n",
    "    to_np = lambda e: np.array(e).reshape(1, -1)\n",
    "    e1, e2 = to_np(e1), to_np(e2)\n",
    "    _cos_sim = cosine_similarity(e1, e2)\n",
    "    return _cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3eb34ee-88ff-43a1-8740-f779ae9e3a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9999999999999976)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_cosine_sim(embedding, embedding)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f63722-8da9-48d5-8014-4bcc535c5e23",
   "metadata": {},
   "source": [
    "# Cache System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3fcc88c-51ff-4fd5-b9a3-97d8a6d53df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diskcache import Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b540d086-4280-417f-94a9-8aaa6986df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Cache(directory=\".cache_course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "715a72dc-2445-4c1a-bd70-b904b8cd6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7cfde2b-eb60-4241-a8a1-f981a43a15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def set_async(key, val, **kwargs):\n",
    "    return await asyncio.to_thread(cache.set, key, val, **kwargs)\n",
    "\n",
    "async def get_async(key, default=None, **kwargs):\n",
    "    return await asyncio.to_thread(cache.get, key, default, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc11eb-2b33-4e59-ae04-b30c6a8b8a03",
   "metadata": {},
   "source": [
    "# Implementing Cached, Retried and Traced Structured Outputs completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c0fe7ba-00c0-4bd4-9d79-f75b8124cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from hashlib import md5\n",
    "\n",
    "def make_cache_key(key_name, **kwargs):\n",
    "    kwargs_string = json.dumps(kwargs, sort_keys=True)\n",
    "    kwargs_hash = md5(kwargs_string.encode('utf-8')).hexdigest()\n",
    "    cache_key = f\"{key_name}__{kwargs_hash}\"\n",
    "    return cache_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df628ad-0bd6-4813-80b5-c871d563c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "def _make_key_for_cached_embedding_with_retry(\n",
    "    *,\n",
    "    model,\n",
    "    input,\n",
    "    **kwargs,\n",
    "):\n",
    "    return make_cache_key(\n",
    "        \"openai_parsed_chat\",\n",
    "        model=model,\n",
    "        input=input,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4243dddd-1c52-4d58-99a3-b930b0579aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.create_embedding_response import CreateEmbeddingResponse\n",
    "from functools import wraps\n",
    "from openai import APITimeoutError, RateLimitError\n",
    "from pydantic import BaseModel\n",
    "import backoff\n",
    "\n",
    "\n",
    "CACHE_MISS_SENTINEL = object()\n",
    "\n",
    "\n",
    "@wraps(client.embeddings.create)\n",
    "async def cached_embedding_with_retry(\n",
    "    *,\n",
    "    model,\n",
    "    input,\n",
    "    **kwargs,\n",
    ") -> CreateEmbeddingResponse:\n",
    "    # CREATE CACHE KEY\n",
    "    cache_key = _make_key_for_cached_embedding_with_retry(\n",
    "        model=model,\n",
    "        input=input,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    cached_value = await get_async(cache_key, default=CACHE_MISS_SENTINEL)\n",
    "    # CACHE MISS\n",
    "    if cached_value is CACHE_MISS_SENTINEL:\n",
    "        @backoff.on_exception(\n",
    "            backoff.expo,\n",
    "            (APITimeoutError, RateLimitError)\n",
    "        )\n",
    "        async def do_call():\n",
    "            return await client.embeddings.create(\n",
    "                model=model,\n",
    "                input=input,\n",
    "                **kwargs\n",
    "            )\n",
    "        embedding = await do_call()\n",
    "        await set_async(cache_key, embedding.model_dump_json())\n",
    "        return embedding\n",
    "    # CACHE HIT\n",
    "    else:\n",
    "        embedding = CreateEmbeddingResponse.model_validate(json.loads(cached_value))\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb089cb1-7e6f-4a9f-ad2e-3500a5633f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = await cached_embedding_with_retry(\n",
    "    input='Union[str, List[str], Iterable[int], Iterable[Iterable[int]]]',\n",
    "    model=EMBED_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0261e31f-480f-4a6f-a3f7-0d1f82886c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010675324127078056"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding(embedding)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abac6674-f96c-474b-a57d-f2c7d98a471a",
   "metadata": {},
   "source": [
    "# Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e670267-f2af-41c0-b5ca-7c10639dda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ffbc7-c1aa-41f1-8899-859eaecd8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv('paul_allen_sent_email_with_questions_v1.csv')\n",
    "emails['questions'] = emails['questions'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3d3af-1205-4b57-9117-7862dd345610",
   "metadata": {},
   "source": [
    "# counting how many questions we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dad008-7173-49e5-a38f-a440169cbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_questions = []\n",
    "\n",
    "for _, row in emails.iterrows():\n",
    "    flat_questions += row.questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82047bfc-ab04-4760-a3d1-e91c4fc4b0a2",
   "metadata": {},
   "source": [
    "## Find the easy duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922be69-90e3-49a0-88c1-6f0bdba4a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_set = {}\n",
    "duplicates = {}\n",
    "\n",
    "for i, row in emails.iterrows():\n",
    "    for question in row.questions:\n",
    "        if question not in questions_set:\n",
    "            questions_set[question] = i\n",
    "        else:\n",
    "            print(i, question, '\\n')\n",
    "            duplicates[question] = questions_set[question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b853f219-7a31-4451-a111-b433d39eb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.iloc[341], emails.iloc[342]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97301bd-5d17-4f25-83c1-dd7a65e43134",
   "metadata": {},
   "source": [
    "### Remove duplicate email 341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f974f49-092e-4af0-b7d5-fe609e8f1f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0818a026-b1c6-4787-8198-7dd01f4f2e8b",
   "metadata": {},
   "source": [
    "## Find likely duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4263f-5fcf-4c87-a920-bc902a2d329b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-course",
   "language": "python",
   "name": "rag-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
